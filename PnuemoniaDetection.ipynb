{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pneumonia Detection using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (5216, 128, 128, 1)\n",
      "Train labels shape: (5216,)\n",
      "Validation images shape: (16, 128, 128, 1)\n",
      "Validation labels shape: (16,)\n",
      "Test images shape: (624, 128, 128, 1)\n",
      "Test labels shape: (624,)\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define paths to the dataset folders\n",
    "TRAIN_PATH = '/Users/vladpavlovich/Downloads/chest_xray/train'\n",
    "VAL_PATH = '/Users/vladpavlovich/Downloads/chest_xray/val'\n",
    "TEST_PATH = '/Users/vladpavlovich/Downloads/chest_xray/test'\n",
    "\n",
    "# Set the target image dimensions\n",
    "IMG_SIZE = 128\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Load, resize, normalize, and add channel dimension to an image.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        return None\n",
    "    img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img_normalized = img_resized / 255.0\n",
    "    img_final = np.expand_dims(img_normalized, axis=-1)  # Add channel dimension\n",
    "    return img_final\n",
    "\n",
    "def load_images_from_directory(directory):\n",
    "    \"\"\"\n",
    "    Load and preprocess all images in a directory with subfolders representing\n",
    "    classes (e.g., 'PNEUMONIA' and 'NORMAL').\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []  # Assuming binary classification with label folders\n",
    "\n",
    "    for label in os.listdir(directory):\n",
    "        label_path = os.path.join(directory, label)  # No 'images' subfolder\n",
    "        \n",
    "        \n",
    "        if os.path.isdir(label_path):\n",
    "            for file_name in os.listdir(label_path):\n",
    "                file_path = os.path.join(label_path, file_name)\n",
    "                \n",
    "                if file_path.endswith(('.png', '.jpg', '.jpeg')):  # Support more image formats\n",
    "                    image = preprocess_image(file_path)\n",
    "                    if image is not None:  # Only append if image loaded successfully\n",
    "                        images.append(image)\n",
    "                        labels.append(1 if label == 'PNEUMONIA' else 0)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# Load images from each dataset directory\n",
    "train_images, train_labels = load_images_from_directory(TRAIN_PATH)\n",
    "val_images, val_labels = load_images_from_directory(VAL_PATH)\n",
    "test_images, test_labels = load_images_from_directory(TEST_PATH)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Validation images shape:\", val_images.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)\n",
    "print(\"Test images shape:\", test_images.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)\n",
    "print(\"Number of classes:\", len(np.unique(train_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1575937 (6.01 MB)\n",
      "Trainable params: 1575937 (6.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_pneumonia_cnn(input_shape=(128, 128, 1)):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # First Convolutional Block\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Optional Fourth Convolutional Block\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten Layer\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Fully Connected (Dense) Layers\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Dropout for regularization\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate and compile the model\n",
    "input_shape = (128, 128, 1)  # Adjust as needed\n",
    "model = build_pneumonia_cnn(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "163/163 [==============================] - 19s 118ms/step - loss: 0.3985 - accuracy: 0.8250 - val_loss: 0.7988 - val_accuracy: 0.6250\n",
      "Epoch 2/20\n",
      "163/163 [==============================] - 19s 116ms/step - loss: 0.1629 - accuracy: 0.9425 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "163/163 [==============================] - 19s 116ms/step - loss: 0.1066 - accuracy: 0.9617 - val_loss: 0.2871 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "163/163 [==============================] - 19s 115ms/step - loss: 0.0811 - accuracy: 0.9732 - val_loss: 0.6361 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "163/163 [==============================] - 19s 116ms/step - loss: 0.0747 - accuracy: 0.9726 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "163/163 [==============================] - 19s 119ms/step - loss: 0.0582 - accuracy: 0.9791 - val_loss: 0.3292 - val_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "163/163 [==============================] - 19s 116ms/step - loss: 0.0538 - accuracy: 0.9818 - val_loss: 0.1084 - val_accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.0420 - accuracy: 0.9850 - val_loss: 0.2552 - val_accuracy: 0.8750\n",
      "Epoch 9/20\n",
      "163/163 [==============================] - 19s 118ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 0.3005 - val_accuracy: 0.9375\n",
      "Epoch 10/20\n",
      "163/163 [==============================] - 20s 120ms/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 0.0778 - val_accuracy: 0.9375\n",
      "Epoch 12/20\n",
      "163/163 [==============================] - 20s 122ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.0645 - val_accuracy: 0.9375\n",
      "Epoch 13/20\n",
      "163/163 [==============================] - 19s 116ms/step - loss: 0.0293 - accuracy: 0.9889 - val_loss: 0.2025 - val_accuracy: 0.9375\n",
      "Epoch 14/20\n",
      "163/163 [==============================] - 19s 115ms/step - loss: 0.0239 - accuracy: 0.9910 - val_loss: 0.1701 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "163/163 [==============================] - 19s 116ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.0898 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "163/163 [==============================] - 21s 126ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "163/163 [==============================] - 20s 122ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "163/163 [==============================] - 19s 119ms/step - loss: 0.0337 - accuracy: 0.9873 - val_loss: 0.2732 - val_accuracy: 0.8750\n",
      "Epoch 20/20\n",
      "163/163 [==============================] - 20s 121ms/step - loss: 0.0221 - accuracy: 0.9908 - val_loss: 0.9348 - val_accuracy: 0.8125\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 3.3793 - accuracy: 0.7083\n",
      "Test Loss: 3.3793\n",
      "Test Accuracy: 0.7083\n",
      "Model saved to pneumonia_detection_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "EPOCHS = 20 \n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(val_images, val_labels)\n",
    ")\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_filename = 'pneumonia_detection_model.h5'\n",
    "\n",
    "model.save(model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 35ms/step\n",
      "Accuracy: 0.7083\n",
      "Precision: 0.6825\n",
      "Recall: 0.9974\n",
      "F1 Score: 0.8104\n",
      "Confusion Matrix:\n",
      "[[ 53 181]\n",
      " [  1 389]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('pneumonia_detection_model.h5')\n",
    "\n",
    "# Get predictions on the test set\n",
    "test_predictions = model.predict(test_images)\n",
    "test_predictions = (test_predictions > 0.5).astype(int).flatten()  # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate various metrics\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision = precision_score(test_labels, test_predictions)\n",
    "recall = recall_score(test_labels, test_predictions)\n",
    "f1 = f1_score(test_labels, test_predictions)\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Image Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "Prediction: Pneumonia\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('pneumonia_detection_model.h5')\n",
    "\n",
    "# Define the image size used in training\n",
    "IMG_SIZE = 128\n",
    "\n",
    "def preprocess_single_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess a single image: load, resize, normalize, and add channel dimension.\n",
    "    \"\"\"\n",
    "    # Load the image in grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found or unable to read.\")\n",
    "    \n",
    "    # Resize to match the input shape of the model\n",
    "    img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    img_normalized = img_resized / 255.0\n",
    "    \n",
    "    # Expand dimensions to add batch and channel dimensions: (1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    img_final = np.expand_dims(img_normalized, axis=(0, -1))\n",
    "    \n",
    "    return img_final\n",
    "\n",
    "def predict_image(image_path):\n",
    "    \"\"\"\n",
    "    Predict if the image shows pneumonia or not.\n",
    "    \"\"\"\n",
    "    # Preprocess the image\n",
    "    processed_image = preprocess_single_image(image_path)\n",
    "    \n",
    "    # Get the model's prediction\n",
    "    prediction = model.predict(processed_image)[0][0]  # Get the single prediction value\n",
    "    \n",
    "    # Interpret the prediction\n",
    "    if prediction > 0.5:\n",
    "        print(\"Prediction: Pneumonia\")\n",
    "    else:\n",
    "        print(\"Prediction: Normal\")\n",
    "\n",
    "# Test with a single image\n",
    "image_path = '/Users/vladpavlovich/Downloads/chest_xray/test/PNEUMONIA/person99_bacteria_474.jpeg'  # Replace with the path to your test image\n",
    "predict_image(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask Front-End for HealthCare providers example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting flask\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /Library/Python/3.9/site-packages (from flask) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /Library/Python/3.9/site-packages (from flask) (3.1.4)\n",
      "Collecting itsdangerous>=2.1.2 (from flask)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from flask)\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in /Library/Python/3.9/site-packages (from flask) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Python/3.9/site-packages (from importlib-metadata>=3.6.0->flask) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Python/3.9/site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: itsdangerous, click, blinker, flask\n",
      "Successfully installed blinker-1.8.2 click-8.1.7 flask-3.0.3 itsdangerous-2.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [04/Nov/2024 20:04:28] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Nov/2024 20:04:28] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 24 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2ec6f63a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [04/Nov/2024 20:04:34] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Set up the path for saving uploaded images\n",
    "UPLOAD_FOLDER = 'uploads/'\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('pneumonia_detection_model.h5')\n",
    "\n",
    "# Define allowed file extensions for upload\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n",
    "\n",
    "def allowed_file(filename):\n",
    "    \"\"\"Check if the file has an allowed extension.\"\"\"\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess the uploaded image for prediction.\"\"\"\n",
    "    IMG_SIZE = 128\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img_normalized = img_resized / 255.0\n",
    "    img_final = np.expand_dims(img_normalized, axis=(0, -1))  # Shape (1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    return img_final\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return '''\n",
    "    <!doctype html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <title>Pneumonia Detection</title>\n",
    "        <style>\n",
    "            body { font-family: Arial, sans-serif; display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; background-color: #f0f2f5; }\n",
    "            .container { text-align: center; padding: 20px; background: white; border-radius: 8px; box-shadow: 0px 4px 8px rgba(0,0,0,0.2); }\n",
    "            h1 { color: #333; }\n",
    "            input[type=\"file\"] { margin: 15px 0; }\n",
    "            #prediction { font-size: 1.2em; font-weight: bold; color: #333; margin-top: 20px; }\n",
    "            .button { background-color: #007bff; color: white; padding: 10px 20px; border: none; border-radius: 5px; cursor: pointer; }\n",
    "            .button:hover { background-color: #0056b3; }\n",
    "            img { max-width: 100%; height: auto; margin-top: 20px; border-radius: 8px; }\n",
    "        </style>\n",
    "        <script src=\"https://code.jquery.com/jquery-3.6.0.min.js\"></script>\n",
    "        <script>\n",
    "            function previewImage(event) {\n",
    "                var reader = new FileReader();\n",
    "                reader.onload = function() {\n",
    "                    var output = document.getElementById('imagePreview');\n",
    "                    output.src = reader.result;\n",
    "                };\n",
    "                reader.readAsDataURL(event.target.files[0]);\n",
    "            }\n",
    "\n",
    "            function uploadImage() {\n",
    "                var formData = new FormData();\n",
    "                var fileInput = document.getElementById(\"fileInput\");\n",
    "                formData.append(\"file\", fileInput.files[0]);\n",
    "\n",
    "                $.ajax({\n",
    "                    url: \"/predict\",\n",
    "                    type: \"POST\",\n",
    "                    data: formData,\n",
    "                    processData: false,\n",
    "                    contentType: false,\n",
    "                    success: function(response) {\n",
    "                        $(\"#prediction\").text(\"Prediction: \" + response.prediction);\n",
    "                    },\n",
    "                    error: function() {\n",
    "                        $(\"#prediction\").text(\"Error: Could not process the image.\");\n",
    "                    }\n",
    "                });\n",
    "            }\n",
    "        </script>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"container\">\n",
    "            <h1>Upload an X-ray Image for Pneumonia Detection</h1>\n",
    "            <input type=\"file\" id=\"fileInput\" accept=\"image/*\" onchange=\"previewImage(event)\">\n",
    "            <img id=\"imagePreview\" src=\"#\" alt=\"Image Preview\" style=\"display: none;\">\n",
    "            <button class=\"button\" onclick=\"uploadImage()\">Upload and Predict</button>\n",
    "            <div id=\"prediction\"></div>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Check if a file is part of the request\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({\"error\": \"No file part in the request\"}), 400\n",
    "    \n",
    "    file = request.files['file']\n",
    "\n",
    "    # Check if the file is selected and has an allowed file extension\n",
    "    if file.filename == '':\n",
    "        return jsonify({\"error\": \"No selected file\"}), 400\n",
    "    if not allowed_file(file.filename):\n",
    "        return jsonify({\"error\": \"File type not allowed\"}), 400\n",
    "\n",
    "    # Save the file\n",
    "    filename = secure_filename(file.filename)\n",
    "    filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "    file.save(filepath)\n",
    "\n",
    "    # Preprocess the image and make a prediction\n",
    "    processed_image = preprocess_image(filepath)\n",
    "    prediction = model.predict(processed_image)[0][0]\n",
    "\n",
    "    # Interpret the prediction\n",
    "    result = \"Pneumonia\" if prediction > 0.5 else \"Normal\"\n",
    "    \n",
    "    # Optionally delete the file after prediction to save space\n",
    "    os.remove(filepath)\n",
    "\n",
    "    return jsonify({\"prediction\": result})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create the upload folder if it doesn't exist\n",
    "    if not os.path.exists(UPLOAD_FOLDER):\n",
    "        os.makedirs(UPLOAD_FOLDER)\n",
    "    \n",
    "    app.run(port=5000, debug=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
